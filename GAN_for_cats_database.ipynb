{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN for cats database.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tijanavukovic1/Realistic-Image-Generation/blob/master/GAN_for_cats_database.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KOrruIEySRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2d632a0b-b894-4255-8ea2-59a5c6697c33"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYIvyym_yTPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "29c9f72c-29ea-4be7-c9c2-ffc15a480e7b"
      },
      "source": [
        "%ldir\n",
        "%cd gdrive/My Drive/psiml projekat/data-efficient-gans-master/data-efficient-gans-master/DiffAugment-biggan-cifar\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drwx------ 3 root     4096 Aug  6 15:14 \u001b[0m\u001b[01;34mdata\u001b[0m/\n",
            "drwx------ 5 root     4096 Aug  5 06:35 \u001b[01;34mdnnlib\u001b[0m/\n",
            "drwx------ 4 root     4096 Aug  6 17:02 \u001b[01;34mlogs\u001b[0m/\n",
            "drwx------ 2 root     4096 Aug  6 15:14 \u001b[01;34m__pycache__\u001b[0m/\n",
            "drwx------ 5 root     4096 Aug  6 16:23 \u001b[01;34msamples\u001b[0m/\n",
            "drwx------ 2 root     4096 Aug  5 06:35 \u001b[01;34mscripts\u001b[0m/\n",
            "drwx------ 2 root     4096 Aug  5 20:13 \u001b[01;34mtrain-images-idx3-ubyte (1)\u001b[0m/\n",
            "drwx------ 4 root     4096 Aug  6 16:23 \u001b[01;34mweights\u001b[0m/\n",
            "[Errno 2] No such file or directory: 'gdrive/My Drive/psiml projekat/data-efficient-gans-master/data-efficient-gans-master/DiffAugment-biggan-cifar'\n",
            "/content/gdrive/My Drive/psiml projekat/data-efficient-gans-master/data-efficient-gans-master/DiffAugment-biggan-cifar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXl5CxOlyWuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "71fa12ae-6c0c-4e2e-ad17-d8193dbadb45"
      },
      "source": [
        "!pip uninstall -y tensorflow tensorflow-probability\n",
        "!pip install tensorflow-gpu==1.15.0"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping tensorflow-probability as it is not installed.\u001b[0m\n",
            "Requirement already satisfied: tensorflow-gpu==1.15.0 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.30.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.18.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.15.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (49.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G69NXDg_yZIh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "13ec9a1d-a506-46ac-ae38-0ffc09e3ccaa"
      },
      "source": [
        "!sh scripts/biggan-mace-augmentovano.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dataset': 'Mace', 'mirror_augment': True, 'num_workers': 8, 'pin_memory': True, 'shuffle': True, 'load_in_mem': False, 'use_multiepoch_sampler': True, 'reset_optim': False, 'load_G_only': False, 'model': 'BigGAN', 'G_param': 'SN', 'D_param': 'SN', 'G_ch': 64, 'D_ch': 64, 'G_depth': 1, 'D_depth': 1, 'D_wide': True, 'G_shared': False, 'fix_G': False, 'shared_dim': 0, 'dim_z': 128, 'z_var': 1.0, 'hier': False, 'cross_replica': False, 'mybn': False, 'G_nl': 'relu', 'D_nl': 'relu', 'G_attn': '0', 'D_attn': '0', 'norm_style': 'bn', 'DiffAugment': 'cutout', 'CR_augment': 'flip,translation', 'num_samples': None, 'CR': 10.0, 'seed': 0, 'G_init': 'N02', 'D_init': 'N02', 'skip_init': False, 'G_lr': 0.0002, 'D_lr': 0.0002, 'G_B1': 0.0, 'D_B1': 0.0, 'G_B2': 0.999, 'D_B2': 0.999, 'batch_size': 50, 'G_batch_size': 0, 'num_G_accumulations': 1, 'num_D_steps': 4, 'num_D_accumulations': 1, 'num_epochs': 20000, 'parallel': True, 'G_fp16': False, 'D_fp16': False, 'D_mixed_precision': False, 'G_mixed_precision': False, 'accumulate_stats': False, 'num_standing_accumulations': 16, 'G_eval_mode': False, 'save_every': 200, 'num_save_copies': 0, 'num_best_copies': 1, 'which_best': 'FID', 'no_fid': False, 'test_every': 4000, 'num_inception_images': 10000, 'hashname': False, 'base_root': '', 'data_root': 'data', 'weights_root': 'weights', 'logs_root': 'logs', 'samples_root': 'samples', 'pbar': 'mine', 'name_suffix': '', 'experiment_name': 'DiffAugment-mace', 'config_from_name': False, 'ema': True, 'ema_decay': 0.9999, 'use_ema': True, 'ema_start': 1000, 'adam_eps': 1e-08, 'BN_eps': 1e-05, 'SN_eps': 1e-08, 'num_G_SVs': 1, 'num_D_SVs': 1, 'num_G_SV_itrs': 1, 'num_D_SV_itrs': 1, 'G_ortho': 0.0, 'D_ortho': 0.0, 'toggle_grads': True, 'which_train_fn': 'GAN', 'load_weights': '', 'resume_name': None, 'resume': False, 'network': None, 'repeat': 1, 'logstyle': '%3.3e', 'log_G_spectra': False, 'log_D_spectra': False, 'sv_log_interval': 10}\n",
            "Experiment name is DiffAugment-mace\n",
            "Param count for Gs initialized parameters: 32033027\n",
            "Param count for Ds initialized parameters: 19543745\n",
            "Preparing EMA for G with decay of 0.9999\n",
            "Initializing EMA parameters to be source parameters...\n",
            "Generator(\n",
            "  (activation): ReLU()\n",
            "  (shared): identity()\n",
            "  (linear): SNLinear(in_features=128, out_features=16384, bias=True)\n",
            "  (blocks): ModuleList(\n",
            "    (0): ModuleList(\n",
            "      (0): GBlock(\n",
            "        (activation): ReLU()\n",
            "        (conv1): SNConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2): SNConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv_sc): SNConv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): ccbn(\n",
            "          out: 1024, in: 1, cross_replica=False\n",
            "          (gain): Embedding(1, 1024)\n",
            "          (bias): Embedding(1, 1024)\n",
            "        )\n",
            "        (bn2): ccbn(\n",
            "          out: 1024, in: 1, cross_replica=False\n",
            "          (gain): Embedding(1, 1024)\n",
            "          (bias): Embedding(1, 1024)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): ModuleList(\n",
            "      (0): GBlock(\n",
            "        (activation): ReLU()\n",
            "        (conv1): SNConv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2): SNConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv_sc): SNConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): ccbn(\n",
            "          out: 1024, in: 1, cross_replica=False\n",
            "          (gain): Embedding(1, 1024)\n",
            "          (bias): Embedding(1, 1024)\n",
            "        )\n",
            "        (bn2): ccbn(\n",
            "          out: 512, in: 1, cross_replica=False\n",
            "          (gain): Embedding(1, 512)\n",
            "          (bias): Embedding(1, 512)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): ModuleList(\n",
            "      (0): GBlock(\n",
            "        (activation): ReLU()\n",
            "        (conv1): SNConv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2): SNConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv_sc): SNConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): ccbn(\n",
            "          out: 512, in: 1, cross_replica=False\n",
            "          (gain): Embedding(1, 512)\n",
            "          (bias): Embedding(1, 512)\n",
            "        )\n",
            "        (bn2): ccbn(\n",
            "          out: 256, in: 1, cross_replica=False\n",
            "          (gain): Embedding(1, 256)\n",
            "          (bias): Embedding(1, 256)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): ModuleList(\n",
            "      (0): GBlock(\n",
            "        (activation): ReLU()\n",
            "        (conv1): SNConv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2): SNConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv_sc): SNConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (bn1): ccbn(\n",
            "          out: 256, in: 1, cross_replica=False\n",
            "          (gain): Embedding(1, 256)\n",
            "          (bias): Embedding(1, 256)\n",
            "        )\n",
            "        (bn2): ccbn(\n",
            "          out: 128, in: 1, cross_replica=False\n",
            "          (gain): Embedding(1, 128)\n",
            "          (bias): Embedding(1, 128)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (output_layer): Sequential(\n",
            "    (0): bn()\n",
            "    (1): ReLU()\n",
            "    (2): SNConv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (activation): ReLU()\n",
            "  (blocks): ModuleList(\n",
            "    (0): ModuleList(\n",
            "      (0): DBlock(\n",
            "        (activation): ReLU()\n",
            "        (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        (conv1): SNConv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2): SNConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv_sc): SNConv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (1): ModuleList(\n",
            "      (0): DBlock(\n",
            "        (activation): ReLU()\n",
            "        (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        (conv1): SNConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2): SNConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv_sc): SNConv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (2): ModuleList(\n",
            "      (0): DBlock(\n",
            "        (activation): ReLU()\n",
            "        (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        (conv1): SNConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2): SNConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv_sc): SNConv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (3): ModuleList(\n",
            "      (0): DBlock(\n",
            "        (activation): ReLU()\n",
            "        (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        (conv1): SNConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2): SNConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv_sc): SNConv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (4): ModuleList(\n",
            "      (0): DBlock(\n",
            "        (activation): ReLU()\n",
            "        (conv1): SNConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2): SNConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv_sc): SNConv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (linear): SNLinear(in_features=1024, out_features=1, bias=True)\n",
            "  (embed): SNEmbedding(1, 1024)\n",
            ")\n",
            "Number of params in G: 32033283 D: 19543745\n",
            "Inception Metrics will be saved to logs/DiffAugment-mace_log.jsonl\n",
            "Training Metrics will be saved to logs/DiffAugment-mace\n",
            "Using dataset root location data/mace\n",
            "Data will be augmented...\n",
            "Loading pre-saved Index file Mace_imgs.npz...\n",
            "Using multiepoch sampler from start_itr 0...\n",
            "Beginning training at epoch 0...\n",
            "Length dataset output is 2200000\n",
            "1/11000 (  0.00%) itr: 0, G_loss : +0.377, D_loss_real : +0.558, D_loss_fake : +1.140, D_loss_CR : +0.011 Saving weights to weights/DiffAugment-mace...\n",
            "Calculating validation accuracy...\n",
            "Using dataset root location data/mace\n",
            "Data will be augmented...\n",
            "Loading pre-saved Index file Mace_imgs.npz...\n",
            "Calculating training accuracy...\n",
            "Using dataset root location data/mace\n",
            "Data will be augmented...\n",
            "Loading pre-saved Index file Mace_imgs.npz...\n",
            "Gathering inception metrics...\n",
            "Itr 0: PYTORCH UNOFFICIAL Inception Score is 1.125 +/- 0.005, PYTORCH UNOFFICIAL FID is 306.3237\n",
            "FID improved over previous best, saving checkpoint...\n",
            "Saving weights to weights/DiffAugment-mace/best...\n",
            "201/11000 (  1.82%) (TE/ET1k: 8:35 / 34:22) itr: 200, G_loss : +1.631, D_loss_real : +0.059, D_loss_fake : +1.143, D_loss_CR : +0.060 Saving weights to weights/DiffAugment-mace...\n",
            "401/11000 (  3.64%) (TE/ET1k: 14:01 / 21:01) itr: 400, G_loss : +0.571, D_loss_real : +1.389, D_loss_fake : +0.069, D_loss_CR : +0.193 Saving weights to weights/DiffAugment-mace...\n",
            "435/11000 (  3.95%) (TE/ET1k: 15:00 / 19:34) "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHETtMFN0J_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}